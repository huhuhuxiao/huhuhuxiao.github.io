<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title> 胡启滨科研周报12(2023-12-18至2023-12-24) | Qibin Hu</title>
<link rel="shortcut icon" href="https://huhuhuxiao.github.io//favicon.ico?v=1704353412064">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://huhuhuxiao.github.io//styles/main.css">
<link rel="alternate" type="application/atom+xml" title=" 胡启滨科研周报12(2023-12-18至2023-12-24) | Qibin Hu - Atom Feed" href="https://huhuhuxiao.github.io//atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="1. 摘要
本周主要是在补课程的大实验，阅读了两篇论文Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors和Text-Image Con..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://huhuhuxiao.github.io/">
  <img class="avatar" src="https://huhuhuxiao.github.io//images/avatar.png?v=1704353412064" alt="">
  </a>
  <h1 class="site-title">
    Qibin Hu
  </h1>
  <p class="site-description">
    When your heart is set on something, you get closer to your goal with each passing day.
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/huhuhuxiao/movie_recommend_system" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
               胡启滨科研周报12(2023-12-18至2023-12-24)
            </h2>
            <div class="post-info">
              <span>
                2023-12-28
              </span>
              <span>
                3 min read
              </span>
              
            </div>
            
              <img class="post-feature-image" src="https://huhuhuxiao.github.io//post-images/hu-qi-bin-ke-yan-zhou-bao-122023-12-18-zhi-2023-12-24.jpg" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h1 id="1-摘要">1. 摘要</h1>
<p>本周主要是在补课程的大实验，阅读了两篇论文Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors和Text-Image Conditioned Diffusion for Consistent Text-to-3D Generation。</p>
<h1 id="2-具体内容">2. 具体内容</h1>
<h2 id="21-text-to-3d-generation-with-bidirectional-diffusion-using-both-2d-and-3d-priors">2.1 Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors</h2>
<figure data-type="image" tabindex="1"><img src="https://huhuhuxiao.github.io//post-images/1704351974789.png" alt="" loading="lazy"></figure>
<h3 id="211-contribution">2.1.1 Contribution</h3>
<p>针对此前text to 3d任务关注将2d生成模型升维到3D空间，并没有结合3D先验的情况。这篇工作结合2D diffusion和3D diffusion的先验， 能使生成的3D模型具有3D结构的高FID以及2D丰富的纹理信息。同时生成时间也从prolificdreamer的3.4h缩短到20min。</p>
<h3 id="212-method">2.1.2 Method</h3>
<figure data-type="image" tabindex="2"><img src="https://huhuhuxiao.github.io//post-images/1704351970405.png" alt="" loading="lazy"></figure>
<center>图1. BiDiff Pipeline</center>
<p>整个过程主要分为两大步骤：1.从3D Diffusion生成模型渲染出2D图片作为2D Diffusion降噪的guidence，从2D Diffusion中渲染的多视图作为3D Diffusion的guidence，这个过程体现了双向扩散。2.用3D Diffusion生成的SDF和2D Diffusion生成的多视图转化成Instant-ngp再进行进行后续SDS Loss优化。</p>
<p><strong>Bidirectional Diffusion</strong></p>
<p><strong>3D Diffusion Model with 2D Guidance</strong></p>
<p><strong>2D Diffusion Model with 3D Guidance</strong></p>
<p><strong>Separate Control of Geometry and Texture</strong></p>
<p><strong>Optimization with BiDiff Initialization</strong></p>
<h3 id="213-results">2.1.3 Results</h3>
<figure data-type="image" tabindex="3"><img src="https://huhuhuxiao.github.io//post-images/1704351963778.png" alt="" loading="lazy"></figure>
<center>图2. 和Prolificdreamer的比较</center>
<h2 id="22-ticdtext-image-conditioned-diffusion-for-consistent-text-to-3d-generation">2.2 (TICD)Text-Image Conditioned Diffusion for Consistent Text-to-3D Generation</h2>
<p><img src="https://huhuhuxiao.github.io//post-images/1704351948108.png" alt="" loading="lazy">​</p>
<h3 id="221-contribution">2.2.1 Contribution</h3>
<p>TICD主要是对此前的<strong>SDS Loss</strong>进行了改进，此前的SDS Loss仅仅是对从NeRF中渲染出的图片与2D Diffusion基于text prompt生成的图片的Loss对NeRF进行优化，TICD则在此基础上新加了多视图条件，也就多了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>L</mi><mrow><mi>S</mi><mi>D</mi><mi>S</mi><mi>i</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">L_{SDSimage}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.328331em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">D</span><span class="mord mathdefault mtight" style="margin-right:0.05764em;">S</span><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">g</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>。能够实现精细的视图连续性和清晰的几何结构。</p>
<h3 id="222-method">2.2.2 Method</h3>
<figure data-type="image" tabindex="4"><img src="https://huhuhuxiao.github.io//post-images/1704351936370.png" alt="" loading="lazy"></figure>
<center>图3. TICD Pipeline</center>
<p>从Pipeline可以看出，相对于此前Text to 3D任务，TICD中新加了下面的Image Conditioned Module，也就多了这个模块的Loss，整个SDS Loss就变成了<br>
<img src="https://huhuhuxiao.github.io//post-images/1704351925697.png" alt="" loading="lazy">​<br>
其中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\lambda_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>是两个Loss的权重。</p>
<h3 id="223-实验结果">2.2.3 实验结果</h3>
<figure data-type="image" tabindex="5"><img src="https://huhuhuxiao.github.io//post-images/1704351993632.png" alt="" loading="lazy"></figure>
<center>图4. 和其他Text to 3D方法的对比</center>
‍
<h1 id="3-存在的问题">3. 存在的问题</h1>
<ol>
<li>这周还是在做课程实验，代码这方面跑的少。</li>
<li>还没有系统研究过目前Text to 3D任务的代码框架，现在只是大概了解每个模块能干些啥</li>
</ol>
<h1 id="4-下周规划">4. 下周规划</h1>
<ol>
<li>看到NUS有一位老师就在这周系统地讲了video diffusion model，一个3小时的视频<a href="https://www.bilibili.com/video/BV1jN4y1879z/?share_source=copy_web&amp;vd_source=78ffdf3de51659b17f1d167b0b177486">【视频扩散模型，三小时入门到精通，Mike Shou, Video Diffusion Models, 2023】</a>，想在下周结合他的视频以及相关论文把video diffusion方向入门一下。</li>
<li>课程实验工作量有点大，还没干完，得继续弄。</li>
</ol>
<p>‍</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li><a href="#1-%E6%91%98%E8%A6%81">1. 摘要</a></li>
<li><a href="#2-%E5%85%B7%E4%BD%93%E5%86%85%E5%AE%B9">2. 具体内容</a>
<ul>
<li><a href="#21-text-to-3d-generation-with-bidirectional-diffusion-using-both-2d-and-3d-priors">2.1 Text-to-3D Generation with Bidirectional Diffusion using both 2D and 3D priors</a>
<ul>
<li><a href="#211-contribution">2.1.1 Contribution</a></li>
<li><a href="#212-method">2.1.2 Method</a></li>
<li><a href="#213-results">2.1.3 Results</a></li>
</ul>
</li>
<li><a href="#22-ticdtext-image-conditioned-diffusion-for-consistent-text-to-3d-generation">2.2 (TICD)Text-Image Conditioned Diffusion for Consistent Text-to-3D Generation</a>
<ul>
<li><a href="#221-contribution">2.2.1 Contribution</a></li>
<li><a href="#222-method">2.2.2 Method</a></li>
<li><a href="#223-%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C">2.2.3 实验结果</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#3-%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98">3. 存在的问题</a></li>
<li><a href="#4-%E4%B8%8B%E5%91%A8%E8%A7%84%E5%88%92">4. 下周规划</a></li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://huhuhuxiao.github.io//atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
